{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load the data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Purpose of the following illustration is to develop a model that would predict if the customer will default in repaying the loan or not."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "        We have taken a very small subset of data, 5000 samples from Kaggle Loan defaulter competition for the purpose of the demo.\n",
      "        The goal of the demo is to understand how various Python based tools are used for multiple usecases in the workflow.\n",
      "        \n",
      "        Finally it should give you some idea about how you can apply the concepts for the entire dataset and improve the model.\n",
      "        "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most machine learning algorithms implemented in scikit-learn expect data to be stored in a\n",
      "**two-dimensional array or matrix**.  The arrays can be\n",
      "either ``numpy`` arrays, or in some cases ``scipy.sparse`` matrices.\n",
      "The size of the array is expected to be `[n_samples, n_features]`\n",
      "\n",
      "- **n_samples:**   The number of samples: each sample is an item to process (e.g. classify).\n",
      "  A sample can be a document, a picture, a sound, a video, a row in database or CSV file,\n",
      "  or whatever you can describe with a fixed set of quantitative traits.\n",
      "- **n_features:**  The number of features or distinct traits that can be used to describe each\n",
      "  item in a quantitative manner.  Features are generally real-valued, but may be boolean or\n",
      "  discrete-valued in some cases.\n",
      "\n",
      "The number of features must be fixed in advance. However it can be very high dimensional\n",
      "(e.g. millions of features) with most of them being zeros for a given sample. This is a case\n",
      "where `scipy.sparse` matrices can be useful, in that they are\n",
      "much more memory-efficient than numpy arrays.\n",
      "\n",
      "Data in scikit-learn is represented as a **feature matrix** and a **label vector**\n",
      "\n",
      "$$\n",
      "{\\rm feature~matrix:~~~} {\\bf X}~=~\\left[\n",
      "\\begin{matrix}\n",
      "x_{11} & x_{12} & \\cdots & x_{1D}\\\\\n",
      "x_{21} & x_{22} & \\cdots & x_{2D}\\\\\n",
      "x_{31} & x_{32} & \\cdots & x_{3D}\\\\\n",
      "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
      "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
      "x_{N1} & x_{N2} & \\cdots & x_{ND}\\\\\n",
      "\\end{matrix}\n",
      "\\right]\n",
      "$$\n",
      "\n",
      "$$\n",
      "{\\rm label~vector:~~~} {\\bf y}~=~ [y_1, y_2, y_3, \\cdots y_N]\n",
      "$$\n",
      "\n",
      "Here there are $N$ samples and $D$ features.\n",
      "\n",
      "[**disclaimer**: The description of this cell is taken from Jake Vanderplas' ipython notebook]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "\n",
      "Demo for GIDs\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "DIR_PATH = \"data//\"\n",
      "TRAIN_FILE = DIR_PATH + \"sample_5000.csv\"\n",
      "\n",
      "#TRAIN_FILE = \"https://raw.githubusercontent.com/parindam/GIDS/master/data/sample_5000.csv\"\n",
      "\n",
      "X_pd = pd.read_csv(TRAIN_FILE, sep=',', warn_bad_lines=True, error_bad_lines=True)\n",
      "\n",
      "print \"The shape of the data is \", X_pd.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The shape of the data is  (5000, 772)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Engineering"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "        Explore the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"What are the various columns of the data ? let's check...\"\n",
      "X_pd.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "What are the various columns of the data ? let's check...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Index([u'Unnamed: 0', u'id', u'f1', u'f2', u'f3', u'f4', u'f5', u'f6', u'f7', u'f8', u'f9', u'f10', u'f13', u'f14', u'f15', u'f16', u'f17', u'f18', u'f19', u'f20', u'f21', u'f22', u'f23', u'f24', u'f25', u'f26', u'f27', u'f28', u'f29', u'f30', u'f31', u'f32', u'f33', u'f34', u'f35', u'f36', u'f37', u'f38', u'f39', u'f40', u'f41', u'f42', u'f43', u'f44', u'f45', u'f46', u'f47', u'f48', u'f49', u'f50', u'f51', u'f52', u'f53', u'f54', u'f55', u'f56', u'f57', u'f58', u'f59', u'f60', u'f61', u'f62', u'f63', u'f64', u'f65', u'f66', u'f67', u'f68', u'f69', u'f70', u'f71', u'f72', u'f73', u'f74', u'f75', u'f76', u'f77', u'f78', u'f79', u'f80', u'f81', u'f82', u'f83', u'f84', u'f85', u'f86', u'f87', u'f88', u'f89', u'f90', u'f91', u'f92', u'f93', u'f94', u'f95', u'f96', u'f97', u'f98', u'f99', u'f100', u'f101', u'f102', u'f103', u'f104', u'f105', u'f106', u'f107', u'f108', u'f109', u'f110', u'f111', u'f112', u'f113', u'f114', u'f115', u'f116', u'f117', u'f118', u'f119', u'f120', u'f121', u'f122', u'f123', u'f124', u'f125', u'f126', u'f127', u'f128', u'f129', u'f130', u'f131', u'f132', u'f133', u'f134', u'f135', u'f136', u'f137', u'f138', u'f139', u'f140', u'f141', u'f142', u'f143', u'f144', u'f145', u'f146', u'f147', u'f148', u'f149', u'f150', u'f151', u'f152', u'f153', u'f154', u'f155', u'f156', u'f157', u'f158', u'f159', u'f160', u'f161', u'f162', u'f163', u'f164', u'f165', u'f166', u'f167', u'f168', u'f169', u'f170', u'f171', u'f172', u'f173', u'f174', u'f175', u'f176', u'f177', u'f178', u'f179', u'f180', u'f181', u'f182', u'f183', u'f184', u'f185', u'f186', u'f187', u'f188', u'f189', u'f190', u'f191', u'f192', u'f193', u'f194', u'f195', u'f196', u'f197', u'f198', u'f199', u'f200', u'f201', u'f202', u'f203', u'f204', u'f205', u'f206', u'f207', u'f208', u'f209', u'f210', u'f211', u'f212', u'f213', u'f214', u'f215', u'f216', u'f217', u'f218', u'f219', u'f220', u'f221', u'f222', u'f223', u'f224', u'f225', u'f226', u'f227', u'f228', u'f229', u'f230', u'f231', u'f232', u'f233', u'f234', u'f235', u'f236', u'f237', u'f238', u'f239', u'f240', u'f241', u'f242', u'f243', u'f244', u'f245', u'f246', u'f247', u'f248', u'f249', u'f250', u'f251', u'f252', u'f253', u'f254', u'f255', u'f256', u'f257', u'f258', u'f259', u'f260', u'f261', u'f262', u'f263', u'f264', u'f265', u'f266', u'f267', u'f268', u'f269', u'f270', u'f271', u'f272', u'f273', u'f274', u'f275', u'f276', u'f277', u'f278', u'f279', u'f280', u'f281', u'f282', u'f283', u'f284', u'f285', u'f286', u'f287', u'f288', u'f289', u'f290', u'f291', u'f292', u'f293', u'f294', u'f295', u'f296', u'f297', u'f298', u'f299', u'f300', u'f301', u'f302', u'f303', u'f304', u'f305', u'f306', u'f307', u'f308', u'f309', u'f310', u'f311', u'f312', u'f313', u'f314', u'f315', u'f316', u'f317', u'f318', u'f319', u'f320', u'f321', u'f322', u'f323', u'f324', u'f325', u'f326', u'f327', u'f328', u'f329', u'f330', u'f331', u'f332', u'f333', u'f334', u'f335', u'f336', u'f337', u'f338', u'f339', u'f340', u'f341', u'f342', u'f343', u'f344', u'f345', u'f346', u'f347', u'f348', u'f349', u'f350', u'f351', u'f352', u'f353', u'f354', u'f355', u'f356', u'f357', u'f358', u'f359', u'f360', u'f361', u'f362', u'f363', u'f364', u'f365', u'f366', u'f367', u'f368', u'f369', u'f370', u'f371', u'f372', u'f373', u'f374', u'f375', u'f376', u'f377', u'f378', u'f379', u'f380', u'f381', u'f382', u'f383', u'f384', u'f385', u'f386', u'f387', u'f388', u'f389', u'f390', u'f391', u'f392', u'f393', u'f394', u'f395', u'f396', u'f397', u'f398', u'f399', u'f400', u'f401', u'f402', u'f403', u'f404', u'f405', u'f406', u'f407', u'f408', u'f409', u'f410', u'f411', u'f412', u'f413', u'f414', u'f415', u'f416', u'f417', u'f418', u'f419', u'f420', u'f421', u'f422', u'f423', u'f424', u'f425', u'f426', u'f427', u'f428', u'f429', u'f430', u'f431', u'f432', u'f433', u'f434', u'f435', u'f436', u'f437', u'f438', u'f439', u'f440', u'f441', u'f442', u'f443', u'f444', u'f445', u'f446', u'f447', u'f448', u'f449', u'f450', u'f451', u'f452', u'f453', u'f454', u'f455', u'f456', u'f457', u'f458', u'f459', u'f460', u'f461', u'f462', u'f463', u'f464', u'f467', u'f468', u'f469', u'f470', u'f471', u'f472', u'f475', u'f476', u'f477', u'f478', u'f479', u'f480', u'f481', u'f482', u'f483', u'f484', u'f485', u'f486', u'f487', u'f488', u'f489', u'f490', u'f491', u'f492', u'f493', u'f494', u'f495', u'f496', u'f497', u'f498', u'f499', u'f500', u'f501', u'f502', u'f503', u'f504', u'f505', u'f506', u'f507', u'f508', u'f509', u'f510', u'f511', u'f512', u'f513', u'f514', u'f515', u'f516', u'f517', u'f518', u'f519', u'f520', u'f521', u'f522', u'f523', u'f524', u'f525', u'f526', u'f527', u'f528', u'f529', u'f530', u'f531', u'f532', u'f533', u'f534', u'f535', u'f536', u'f537', u'f538', u'f539', u'f540', u'f541', u'f542', u'f543', u'f544', u'f545', u'f546', u'f547', u'f548', u'f549', u'f550', u'f551', u'f552', u'f553', u'f554', u'f555', u'f556', u'f557', u'f558', u'f559', u'f560', u'f561', u'f562', u'f563', u'f564', u'f565', u'f566', u'f567', u'f568', u'f569', u'f570', u'f571', u'f572', u'f573', u'f574', u'f575', u'f576', u'f577', u'f578', u'f579', u'f580', u'f581', u'f582', u'f583', u'f584', u'f585', u'f586', u'f587', u'f588', u'f589', u'f590', u'f591', u'f592', u'f593', u'f594', u'f595', u'f596', u'f597', u'f598', u'f599', u'f600', u'f601', u'f604', u'f606', u'f607', u'f608', u'f609', u'f610', u'f611', u'f612', u'f613', u'f614', u'f615', u'f616', u'f617', u'f618', u'f619', u'f620', u'f621', u'f622', u'f623', u'f624', u'f625', u'f626', u'f627', u'f628', u'f629', u'f630', u'f631', u'f632', u'f633', u'f634', u'f635', u'f636', u'f637', u'f638', u'f639', u'f640', u'f641', u'f642', u'f643', u'f644', u'f645', u'f646', u'f647', u'f648', u'f649', u'f650', u'f651', u'f652', u'f653', u'f654', u'f655', u'f656', u'f657', u'f658', u'f659', u'f660', u'f661', u'f662', u'f663', u'f664', u'f665', u'f666', u'f667', u'f668', u'f669', u'f670', u'f671', u'f672', u'f673', u'f674', u'f675', u'f676', u'f677', u'f678', u'f679', u'f680', u'f681', u'f682', u'f683', u'f684', u'f685', u'f686', u'f687', u'f688', u'f689', u'f690', u'f691', u'f692', u'f693', u'f694', u'f695', u'f696', u'f697', u'f698', u'f699', u'f700', u'f701', u'f702', u'f703', u'f704', u'f705', u'f706', u'f707', u'f708', u'f709', u'f710', u'f711', u'f712', u'f713', u'f714', u'f715', u'f716', u'f717', u'f718', u'f719', u'f720', u'f721', u'f722', u'f723', u'f724', u'f725', u'f726', u'f727', u'f728', u'f729', u'f730', u'f731', u'f732', u'f733', u'f734', u'f735', u'f736', u'f737', u'f738', u'f739', u'f740', u'f741', u'f742', u'f743', u'f744', u'f745', u'f746', u'f747', u'f748', u'f749', u'f750', u'f751', u'f752', u'f753', u'f754', u'f755', u'f756', u'f757', u'f758', u'f759', u'f760', u'f761', u'f762', u'f763', u'f764', u'f765', u'f766', u'f767', u'f768', u'f769', u'f770', u'f771', u'f772', u'f773', u'f774', u'f775', u'f776', u'f777', u'f778', u'loss'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"And some values ...\"\n",
      "X_pd.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "And some values ...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "array([[0L, 1L, 126L, ..., 0L, 5L, 0L],\n",
        "       [1L, 2L, 121L, ..., 0L, 5L, 0L],\n",
        "       [2L, 3L, 126L, ..., 0L, 5L, 0L],\n",
        "       ..., \n",
        "       [4997L, 4998L, 128L, ..., 0L, 513L, 0L],\n",
        "       [4998L, 4999L, 133L, ..., 0L, 513L, 0L],\n",
        "       [4999L, 5000L, 130L, ..., 0L, 513L, 0L]], dtype=object)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "\n",
      "let's take a feature and describe the variable\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"describe() will give you statistical summary of the data ...\"\n",
      "X_pd['loss'].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "describe() will give you statistical summary of the data ...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "count    5000.000000\n",
        "mean        0.761000\n",
        "std         4.192063\n",
        "min         0.000000\n",
        "25%         0.000000\n",
        "50%         0.000000\n",
        "75%         0.000000\n",
        "max       100.000000\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scatterplot with the variable and the loss column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "\n",
      "import pylab as pl\n",
      "\n",
      "pl.figure(2, figsize=(12, 6))\n",
      "pl.scatter(X_pd.f768, X_pd.loss, c=X_pd.loss, cmap=pl.cm.Paired)\n",
      "pl.xlabel('X_pd.f768')\n",
      "pl.ylabel('X_pd.loss')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<matplotlib.text.Text at 0xfc7da90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAGACAYAAACTE8U/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd0VVXCxuH33JLcNEgIJAFCT0KTJiWgIEEJIooFkREs\nsWBDp4hDkbFgJeioyMzYFbEh2AAdQBQMvUmHSO8tlPR+2/cHThw/0YnAybmQ37NW1sq59fUA5r07\ne+9j+P1+vwAAAACcVTarAwAAAADnI4o2AAAAYAKKNgAAAGACijYAAABgAoo2AAAAYAKKNgAAAGCC\nKinad9xxh2JjY9WmTZuK20aMGKGWLVuqXbt2GjBggPLy8iruGzdunBITE9WiRQvNnTu3KiICAAAA\nZ1WVFO3bb79dc+bM+dltffr00ebNm7V+/XolJSVp3LhxkqTMzExNnTpVmZmZmjNnjoYNGyafz1cV\nMQEAAICzpkqKdo8ePRQVFfWz21JTU2WznXz75ORkHThwQJI0Y8YMDR48WE6nU40bN1ZCQoJWrlxZ\nFTEBAACAsyYg5mi/88476tevnyTp0KFDio+Pr7gvPj5eBw8etCoaAAAAcFosL9rPPPOMgoKCNGTI\nkF99jGEYVZgIAAAAOHMOK9/83Xff1axZszRv3ryK2+rXr6/9+/dXHB84cED169f/xXMTEhK0c+fO\nKskJAACA6qtZs2basWPH736eZSPac+bM0fPPP68ZM2bI5XJV3H711Vfr448/Vnl5uXbv3q3t27er\nS5cuv3j+zp075ff7+bLo6/HHH7c8Q3X+4vxz7qvrF+ef819dvzj31n6d7uBulYxoDx48WAsWLNDx\n48fVoEEDPfHEExo3bpzKy8uVmpoqSerWrZteeeUVtWrVSoMGDVKrVq3kcDj0yiuvMHUEAAAA55wq\nKdpTpkz5xW133HHHrz5+zJgxGjNmjJmRAAAAAFNZvhgS56aUlBSrI1RrnH/rcO6txfm3FuffOpz7\nc5Ph9/v9Voc4HYZh6ByNDgAAgHPI6fZORrQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAA\nABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAA\nE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAAT\nULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQ\ntAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1RJ\n0b7jjjsUGxurNm3aVNyWnZ2t1NRUJSUlqU+fPsrNza24b9y4cUpMTFSLFi00d+7cqogIAAAAnFVV\nUrRvv/12zZkz52e3paenKzU1Vdu2bdNll12m9PR0SVJmZqamTp2qzMxMzZkzR8OGDZPP56uKmAAA\nAMBZUyVFu0ePHoqKivrZbTNnzlRaWpokKS0tTdOnT5ckzZgxQ4MHD5bT6VTjxo2VkJCglStXVkVM\nVMJDw4crJjJCMTXDdffQoVbHAQAACFgOq944KytLsbGxkqTY2FhlZWVJkg4dOqSuXbtWPC4+Pl4H\nDx60JCN+7rHHHtOb/5qoP3WNk8MwNPHDyXI6nfrXq69aHQ0AACDgBMRiSMMwZBjGb94P673/zpu6\nvUMddakfoQvrheueTrH64pMpVscCAAAISJaNaMfGxurIkSOKi4vT4cOHFRMTI0mqX7++9u/fX/G4\nAwcOqH79+qd8jbFjx1Z8n5KSopSUFDMjV3t2u10lHnfFcYnbJ7vdbmEiAACAsy8jI0MZGRln/DqG\n3+/3n3mc/23Pnj3q37+/Nm7cKEkaOXKkoqOjNWrUKKWnpys3N1fp6enKzMzUkCFDtHLlSh08eFC9\ne/fWjh07fjGqbRiGqig6fjRp0iTdd/dQ3XhBtByGoQ83Htcz45/X8OHDrY4GAABgmtPtnVUyoj14\n8GAtWLBAx48fV4MGDfTkk09q9OjRGjRokN5++201btxY06ZNkyS1atVKgwYNUqtWreRwOPTKK68w\ndSRA3H777XI6nUp/+kn5/T69OHGs7rvvPqtjAQAABKQqG9E+2xjRBgAAQFU43d4ZEIshAQAAgPMN\nRRsAAAAwAUUbAAAAMAFFGwAAADABRRsAAAAwAUUbAAAAMAFFGwAAADABRRsAAAAwAUUbAAAAMAFF\nGwAAADABRRsAAAAwAUUbAAAAMAFFGwAAADABRRsAAAAwAUUbAAAAMAFFGwAAADABRRsAAAAwAUUb\nAAAAMAFFGwAAADABRRsAAAAwAUUbAAAAMAFFGwAAADABRRsAAAAwAUUbAAAAMAFFGwAAADABRRsA\nAAAwAUUbAAAAMAFFGwAAADABRRsAAAAwAUUbAAAAMAFFGwAAADABRRsAAAAwAUUbAAAAMAFFGwAA\nADABRRsAAAAwAUUbAAAAMAFFGwAAADABRRsAAAAwAUUbAAAAMIHlRXvcuHFq3bq12rRpoyFDhqis\nrEzZ2dlKTU1VUlKS+vTpo9zcXKtjAgAAAL+LpUV7z549evPNN7VmzRpt3LhRXq9XH3/8sdLT05Wa\nmqpt27bpsssuU3p6upUxAQAAgN/N0qJdo0YNOZ1OFRcXy+PxqLi4WPXq1dPMmTOVlpYmSUpLS9P0\n6dOtjAkAAAD8bpYW7Vq1aumhhx5Sw4YNVa9ePUVGRio1NVVZWVmKjY2VJMXGxiorK8vKmAAAAMDv\nZmnR3rlzpyZMmKA9e/bo0KFDKiws1AcffPCzxxiGIcMwLEoIAAAAnB6HlW/+/fff66KLLlJ0dLQk\nacCAAVq2bJni4uJ05MgRxcXF6fDhw4qJiTnl88eOHVvxfUpKilJSUqogNQAAAM5nGRkZysjIOOPX\nMfx+v//M45ye9evX66abbtKqVavkcrl02223qUuXLtq7d6+io6M1atQopaenKzc39xcLIg3DkIXR\nAQAAUE2cbu+0tGhL0nPPPafJkyfLZrPpwgsv1FtvvaWCggINGjRI+/btU+PGjTVt2jRFRkb+7HkU\nbQAAAFSFc7Zony6KNgAAAKrC6fZOyy9YAwAAAJyPKNoAAACACSjaAAAAgAko2gAAAIAJKNoAAACA\nCSjaAAAAgAko2gAAAIAJKNoAAACACSjaAAAAgAko2gAAAIAJKNoAAACACSjaAAAAgAko2gAAAIAJ\nKNoAAACACSjaAAAAgAko2gAAAIAJKNoAAACACSjaAAAAgAko2gAAAIAJKNoAAACACSjaAAAAgAko\n2gAAAIAJKNoAAACACSjaAAAAgAko2gAAAIAJKNoAAACACSjaAAAAgAko2gAAAIAJKNr43QoKCpSX\nl2d1DAAAgIBG0UaleTwe3XbTjYqLiVb9uBgNvPYqlZaWWh0LAAAgIFG0UWl/f3689q/9Rnsfrq/9\nY+qpbPcyPfn4o1bHAgAACEgUbVTaisULdEcHh8KCbHI5bbqrY5BWLF1odazf5cMPP9CAK3vr5kHX\nad26dVbHAQAA5zGKNiqtQeOmWrzPK7/fL0lavNejho2aWJyq8l5/7VWNfeheDQxdoI4FXym1V3dl\nZmZaHQsAAJynDP9/WtM5xjAMnaPRz1nHjx9XysXJilSenHZD+4uCtXDZStWrV8/qaJXSrkUT/bP7\nQV3c8OTny0fmeeVN/ovGP/e8xckAAEAgO93e6TAhC85TtWvX1sq1G/Xdd9/J5/MpJSVFERERVseq\nNL/fL5vx07HdkDx+n3WBAADAeY0RbVQb//zHRP0rfYyevqRMRwqksUuCNX/hMrVp08bqaAAAIIAx\nog38D/c/8EeFhoZp0sfvKjQsQrPmPkHJBgAApmFEGwAAAPgNjGgD/8+BAwc0efJkud1u3XDDDWrd\nurXVkQAAQDVi+fZ+ubm5GjhwoFq2bKlWrVppxYoVys7OVmpqqpKSktSnTx/l5uZaHRPnmD179qjL\nhW11cO4LKl78slK6J2vp0qVWxwIAANWI5VNH0tLS1LNnT91xxx3yeDwqKirSM888o9q1a2vkyJEa\nP368cnJylJ6e/rPnMXUEv+VPD9yr8O3T9Ey/k7uiTF5ZqKlHWmn2vEUWJwMAAOea0+2dlo5o5+Xl\nadGiRbrjjjskSQ6HQzVr1tTMmTOVlpYm6WQRnz59upUxcQ4qyM1Ro8if9vJrFOVQQX6ehYkAAEB1\nY2nR3r17t+rUqaPbb79dF154oe666y4VFRUpKytLsbGxkqTY2FhlZWVZGRPnoP4D/qDnFrq1cm+Z\nfjji1pivy3XVgEFWxwIAANWIpUXb4/FozZo1GjZsmNasWaOwsLBTThExDONXXgE4tQEDBmjk4+N1\n63SHrnzfq96D7tXIUWOsjgUAAKoRS3cdiY+PV3x8vDp37ixJGjhwoMaNG6e4uDgdOXJEcXFxOnz4\nsGJiYk75/LFjx1Z8n5KSopSUlCpIjXPFPffep3vuvc/qGAAA4ByTkZGhjIyMM34dyxdDXnLJJXrr\nrbeUlJSksWPHqri4WJIUHR2tUaNGKT09Xbm5uSyGBAAAgCVOt3dWqmgvXrxY7du3V3h4uN5//32t\nXbtWf/7zn9WoUaPTCvvf1q9fr6FDh6q8vFzNmjXTpEmT5PV6NWjQIO3bt0+NGzfWtGnTFBkZ+fPg\nFG0AAABUAVOLdps2bbRhwwZt2LBBt912m4YOHapp06ZpwYIFpxX2bKBoAwAAoCqYur2fw+GQYRia\nPn267r//ft1///0qKCj43W8GAAAAVBeVWgwZERGhZ599Vh988IEWLVokr9crt9ttdjYAAADgnFWp\nEe2pU6fK5XLpnXfeUVxcnA4ePKgRI0aYnQ0AAAA4Z1VqjnZRUZFcLpfsdru2bt2qrVu3qm/fvgoK\nCqqKjKfEHG0AAABUBVMXQ1544YVavHixcnJydPHFF6tz584KCgrShx9+eFphzwaKtjX8fr92794t\nn8+npk2bymaz9JpHAAAApjN1MaTf71doaKg+//xzDRs2TJ988ok2bdr0u98M57bS0lJddUUf9ejW\nSb26J+uylB4sigUAAPgVlR6OXLZsmT788ENdeeWVkiSfz2daKASmZ595SsGl+7XrvT9o13t/UIPQ\nfD36yMNWxwIAAAhIldp1ZMKECRo3bpyuu+46tW7dWjt37lSvXr3MzoYAs2n9WjWpE6K+o76Uz+9X\nlxaxWrNujdWxAAAAAtLvugR7QUGBDMNQeHi4mZkqhTnaVe/6Addp0fyv9cZfesluM3TfxAy1aNtZ\n387/zupoAAAApjF1jvbGjRvVoUMHtW7dWq1atVLHjh2Zo10NGT6P0u/spv5dm6hfl8aacF8Pycd+\n6gAAAKdSqaJ9991368UXX9S+ffu0b98+vfDCC7r77rvNzoYAExIaosKSn4p1YYlbYWFhFiYCAAAI\nXJWao11cXPyzOdkpKSkqKioyLRQC0wN/fkhXXdFHZW6vHHabxn2yQR9/8oXVsQAAAAJSpUa0mzRp\noqeeekp79uzR7t279fTTT6tp06ZmZ0OASU5O1uy587Td31yby5vq8xn/1qWXXmp1LAAAgIBUqcWQ\n2dnZevzxx7VkyRJJUo8ePTR27FhFRUWZHvDXsBgSAAAAVcHUK0MGIoo2AAAAqsLp9s7fnKPdv3//\n33zDmTNn/u43BAAAAKqD3yzaDz300K/eZxjGWQ8DAAAAnC+YOgIAAAD8BlMvWHMqjz/++Ok+FQAA\nADjvnXbR7tSp09nMAQAAAJxXmDoCAAAA/AZTdh354x//+KtvYBiGJk6c+LvfEAAAAKgOfnPqSMeO\nHdWxY0eVlZVpzZo1SkpKUmJiotatW6fy8vKqyggAAACccyo1dSQ5OVmLFy+W0+mUJLndbnXv3l0r\nVqwwPeCvYeoIAAAAqoKpu47k5uYqPz+/4rigoEC5ubm/+80AAACA6uI352j/x+jRo3XhhRcqJSVF\nkrRgwQKNHTvWxFgAAADAua3Su44cPnxYK1eulHRyKklcXJypwf4Xpo4AAACgKpiy68h/+P1+LV26\nVIsXL5ZhGPL5fLruuut+95sBAAAA1UWlRrTvu+8+7dy5U4MHD5bf79e0adPUtGlTvfLKK1WR8ZQY\n0QYAAEBVON3eWami3aJFC2VmZspmO7l20ufzqVWrVtqyZcvvT3qWULQBAABQFUzddSQhIUH79u2r\nON63b58SEhJ+95sBAAAA1UWlinZ+fr5atmypnj17KiUlRa1atVJBQYH69++vq6++2uyMCCCvvfKK\nWjdpopaNGumF557jtwoAAAC/olKLIZ988slf3PafIXTDMM56KASmjz78UM+PGaOJMbGyG4aGp6cr\nLDxc9w4bZnU0AACAgFPp7f1+S7du3bRs2bKzkafSmKNd9W648kqlbNqs62vVkiTNzcvT+3Xj9M2S\nJRYnAwAAMI+pc7T/l9LS0rPxMghwYTVqKMvrqTg+4nYrokYNCxMBAAAErkpNHQEkacQjjyjloot0\nxO2WTdKnxcWafYppRQAAADhLI9qoHpo3b65LevbUeydO6N3sbHXq3Flt27a1OhYAAEBA+s2i/d9b\n+v1/ixYtOuthENj+/txzOrFmjbb1TtXO3qmy7dihJx591OpYAAAAAek3i3ZKSorGjx8vr9dbcduR\nI0d088036y9/+UvFbe+99555CREwVixcqOTQUP1l40bdv2G9OoSEaAUfuAAAAE7pN4v26tWrtWvX\nLrVv317z5s3ThAkTlJycrK5du2rVqlUVj2vTps0ZhfB6verQoYP69+8vScrOzlZqaqqSkpLUp08f\n5ebmntHr4+zILizUa3v2qGeDePVp1Eiv7dmjnMJCq2MBAAAEpEpt7zdhwgQNHz5c9erV07Jly9Sg\nQYOzGuLFF1/U6tWrVVBQoJkzZ2rkyJGqXbu2Ro4cqfHjxysnJ0fp6ek/D872flUuMT5ew+rX1+1J\nSZKkT3fv1pNbtmjf8eMWJwMAADCPKdv75eTk6J577tGkSZM0e/ZsDRw4UFdccYXmzZt32kH/vwMH\nDmjWrFkaOnRoxX/AzJkzlZaWJklKS0vT9OnTz9r74fQZhiH7f12gyG6zccEiAACAX/GbRbtjx45K\nSEjQ6tWrdfnll2vChAn64IMP9Mgjj2jw4MFnJcCDDz6o559/XjbbT1GysrIUGxsrSYqNjVVWVtZZ\neS+cmbv+9Cc9smaNPt61S5/t2aOHVqzQkKFDrY4FAAAQkH5zH+0FCxb8YppI+/bttXTpUr355ptn\n/OZfffWVYmJi1KFDB2VkZJzyMYZh/Oqo6dixYyu+T0lJUUpKyhlnwq/761//qozvvtOY+fMlSW26\ndNGzzz5rcSoAAICzKyMj41e76e9xVi7BfrrGjBmj999/Xw6HQ6WlpcrPz9eAAQO0atUqZWRkKC4u\nTocPH1avXr20ZcuWnz2XOdpV791JkzT+b3/T5CuukMMwNHTuXN02fLj+9F870AAAAJxvTrd3Wlq0\n/9uCBQv097//XV9++aVGjhyp6OhojRo1Sunp6crNzWUxZAAYePXVukrSoFatJElzdu7Uq1lZ+mbh\nQmuDAQAAmMiUxZBV7T9TREaPHq1vvvlGSUlJmj9/vkaPHm1xMkiSYbNp139ttbg7N1c2u93CRAAA\nAIErYEa0fy9GtKve9ddeq/lff62rExNlMwx9vmWLOnXtqnkLFlgdDQAAwDSn2zt/czEk8N/8Ho+a\nRkfri23bZBiGmkRHy+/xWB0LAAAgIFG0UWm2oCDVCA3VwXHPym6z6ca331Gpy2V1LAAAgIAUUHO0\nEdi85eW6u0d3uZxOOe123dOju7xlZVbHAgAACEgUbVRak4QEzdu+vWKO0rxt29UkMdHiVAAAAIGJ\nxZCotNzcXPXq0UO+ggI5bTYV2mxasGRJxVU8AQAAzkcshoTp3G63iktK5DR88htSaVm53G631bEA\nAAACEiPaqLQ/PXC/8rdt1COD+kmSJsz4Vvk1Y/XeBx9anAwAAMA858UFaxDY9u3Zo45NG1Qcd2zW\nUAf27bMwEQAAQOCiaKPSunXvoY+XrFFRaZlKy936cNH36nbxxVbHAgAACEhMHUGleTweDR40SDO+\n/FKGIV3aq5emz/xSwcHBVkcDAAAwDYshYboffvhB8xd8p36XtpXNblPGspVat26dkpOTrY4GAAAQ\ncBjRRqXdcvMQ2cv266KOifL5/VqfuU8Hc12a+eW/rY4GAABgGka0Ybr8/Dxt2rBNM75ZI8NmqGZ4\niBo04oI1AAAAp0LRRqU5nMEKqRGkp8YMkmGT3nljgZxBLqtjAQAABCR2HUGllZWXqNvFibI7bLLZ\nbLqoe6LKykusjgUAABCQKNqotOCgEK1dvUc+n19+v19rV++VKzjE6lgAAAABiakjqLRyd5n27T+h\npx77XDa7Te5yj1o0r2V1LAAAgIBE0UalhYaFqnOvZmqUUFt+n3T0YK6KjoRbHQsAACAgUbRRacP/\n8ldd3jdV3t5e2ew2LZu7S59+8rnVsX6T339ymovNxiwpAABQtWgfqLSOHTuqfny85n6xUXM+Wa+o\n6Fq6OEAvwe73+/XoY48oLDxUIaEupd1+q8rLy62OBQAAqhGKNipt0OBBOpS7T9e80E3XvXyx8n3Z\nurJ/P6tjndKkdyfpzQ9eV5+nOqj/i8lasO5bPfLY36yOBQAAqhGuDIlKq9sgVrHdwlWcWyb5pfCY\nEO359piys3KtjvYLfxgySHtcG9TsknqSpKPbcnV8rkfrvt9gcTIAAHCuOd3eyYg2Ks2QTZu/2it3\nuF/eKGnjF7sln9WpTq1e3foqOFhWcZy3v0ixMXEWJgIAANUNI9qotLoN4xR6kUO12tSU/H7l7yrS\n0X/nKScAR7SPHj2qTl06KijWkCPYpqOZeVqYsUgXXHCB1dEAAMA55nR7J0UblRYTX0dFRqG8ZT4Z\nNsmw2+QsdyrvWL7V0U4pNzdX06dPV3l5ufr166f4+HirIwEAgHMQRRumi4gMl6OZXYl/bCRJ2vX2\nARWuL1ZpfqnFyQAAAMzDHG2YziOPaneLlGEzZNgM1e4aKX+gTtKW9Mknn6htp7Zq2a6FXpzwIh/M\nAABAlaJoo9KiatTSieW58vv88vv8OrE8R2EhYVbHOqWvv/5aQ++/U87LPYoY6NS4ic/oH//6h9Wx\nAABANcLUEVTavn37lNAqQX677+T5L/dr7cp1AbnA8Ka0m7Q2aLka9Dm508iJDbnyfROkNcvXWpwM\nAACca063d3IJdlRaw4YNVZhdqDfeeEMej0f33HOPQkJCrI51SoYMlee5K47dhR7Z/E4LEwEAgOqG\noo3fJSgoSHfccYd8Pt/PSnZpaamCgoJkswXGbCSbDO396pD8Xr/sIXbtmXFQbVq2sToWAAD/U3Fx\nsUJCQmQYhtVRcIYCoxXhnFBeXq4L2rVWeES4atSsoWbNm+rAgQPqlZqiiBoRCg0P1fMvPG91TElS\nmadMidc1lOE25M3xqNVNTeXxe6yOBQDAr1q9erUaNI5XzciaiouP06JFi6yOhDNE0UalXX/D9coq\nOaQhU6/QzZ/2U3Fwvi7s0kHHXAd18xdX6JpXL9H4l9I1e/Zsq6Oqb+oVOrE8Xwn9G6jljU2V/X2B\n+vbua3UsAABOqbi4WFdc1VeJN9XVLTP6qf19TXXNgKuVnZ1tdTScAYo2Ku37davU8KI4rXp7s1a8\ntlHxXWKVX5Sv1gObyGa3KTw2VA17xWjRYus/gd+WdpvuvfV+LRq+Tt/cvUKXtuujp5542upYAACc\n0q5du2QLMdSkR30ZhqH4TrGqERemzMxMq6PhDFC0UWlFeUXa9OlO1W0arfotYrRx2nZ5Sj06tu3k\nJdj9Pr/ydhSrfr36Fic9uTr4icefUGF+oUqLS/Xu2+8qKCjI6lgAAJxSTEyMCo4Xqeh4iSSpNL9c\nOYfyFRcXZ3EynAkWQ6LSyj1l6n5nO7W/rrkkKTjMqe/+sVprXt+mI8tzVHSsWLHh9XTnnXdanPQn\nLCQBAJwLYmJi9Ogjj+q5v45XvXa1dWRztu67d5gSEhKsjoYzQNFG5dkMOVw//ZVxBDtk2KT1q9dr\n4cKFioiIUL9+/Rg5BgDgNIweOVqXplyqzZs3KykpSRdffLHVkXCGuGANKs3usMsZ6lCfEV1lsxua\n+/xylRaUy+cJ3MuwAwAAnKnT7Z2WztHev3+/evXqpdatW+uCCy7QxIkTJUnZ2dlKTU1VUlKS+vTp\no9zcXCtj4keu8CDVjA3TN39frq/HL1dYVIiCQ7kIDAAAwKlYOqJ95MgRHTlyRO3bt1dhYaE6duyo\n6dOna9KkSapdu7ZGjhyp8ePHKycnR+np6T97LiPaVc8Z5FBYrRClpfeT3WHTe2NmK+9oodyl7E8N\nAADOX+fkiHZcXJzat28vSQoPD1fLli118OBBzZw5U2lpaZKktLQ0TZ8+3cqY+FFwqFNXPXCxGret\nqwatYnXt8EsU5HJqw4YNeu655/Taa6+poKDA6pgAAAABIWC299uzZ4/Wrl2r5ORkZWVlKTY2VpIU\nGxurrKwsi9NBkvw+Ke9YYcVx3rEiecs9Srn0En276XO9/dk/1Tm5k/Lz8y1MCQAAEBgCYteRwsJC\nXX/99Xr55ZcVERHxs/sMw2CLtgAREhyqr19fodyjhXI47VryyQY5HHbd8nQftb64qSTpnVGz9Pbb\nb+vBBx+0OC0AAIC1LC/abrdb119/vW655RZde+21kk6OYh85ckRxcXE6fPiwYmJiTvncsWPHVnyf\nkpKilJSUKkhcfbnCghUWE63ln22SJMU1idaxA7mKbVSr4jG1G0ToxIkTVkUEAAA4YxkZGcrIyDjj\n17F0MaTf71daWpqio6P10ksvVdw+cuRIRUdHa9SoUUpPT1dubi6LIQNAVK1IxTSpob9Nuk02u6Hn\n7/1I29buU4vkRrrp0cuVfThfE++bpkdGP67Ro0dbHRcAAOCsON3eaWnRXrx4sS655BK1bdu2YnrI\nuHHj1KXpr4fhAAAgAElEQVRLFw0aNEj79u1T48aNNW3aNEVGRv7suRTtqhdVu4Z639RJh3edkN/v\nV4PmMfryzcVqc1EzbVq+S67QYDVrU0+9O12nZ555xuq4AACc0uLFi3XXPXeqqLhQXTtfpI8/niqb\nzfplayUlJXrq6Se1fuM6tWjeSmMfG/uLKbWwxjlZtM8ERbvqRdeOUml5qdJGXSmH0653x32l8jKP\n7nrqavW4pp18Xp+ev+tj3TXkT7r33nutjgsAwC9s3rxZnTpfqP539FDjFnU19R/fKj6miZYsWmpp\nLr/fr8v7pqrEkaOLrmytNfO3qeCgT4sXLZXDYflM32qPog3T9enbWwnda+ryId0kSQtnrtXcSet0\n8OAhxTSIVGFeiRKbtNDXs+cGxGXYy8vLtWTJErndbnXr1o1RAQCoprZu3art27erefPmGjt2rHZn\nb9Sof90qSTp+OFf39kqXu9zaa0Ls2LFDF1/SVa9mjJDdYZfP59ODV0zUp1Omq1OnTpZmw+n3Tj4i\nodKCgoJks//0qzWb3aagoCDZ7Q7ZHcHy+0vlcrkC4tdvhYWF6nVZinIKs+UKDVbhiRItWrBIDRo0\nsDoaAKAKTfzHyxr75BNq0rKhdmfuVWKzJAXV+ennlN1h/c8s6eSItmEY0o9TaQ3DkM3GoOK5jhFt\nVFpiUqIOHz2oux67Rna7XW8+OUPuMq/+MOIa9bi2qzxur/7xwFv689DhGjp0qKVZH3n0EWWs/Ua3\nPz1YhmHoy9e/lv1EqD6d+qmluQAAVefAgQNq3aa1HpnyoKLrRunYgeN6avBLcrvLNeiB3mrcoq4+\neulr1QqL06oV31ua1efzKeWynnJElql7/7ZaPX+LDv9QqBXLV8npdFqaDefolSFxbikqKZRht+vN\nJ2botcc+l8frk9vjVqvk5pIkh9OuZh0aadeuXRYnlXbu3qmkzs0qFtm26JKoXbt2WpwKAFCV9u/f\nr7iGMYquGyVJqhNfWzH16uilFyZo6Ywf9NbYr9SicVvL52dLks1m06wvZ6tt425a9NF2Nax5geZ9\n+x0l+xxH0Ual5ecWyBkUpLtfflD3/uuvCo+sIfml+VMXye/3qyCnUEu+XBUQc6FdTpcWfLZUZSVl\n8nq8mj91sYKcwVbHAgBUocTERB09cEzb154cANqyarvyTuTppptu0s5tu3V4f5b+/dWsgFhXJEnh\n4eGa8NLL+u7bBXr1X68pKirK6kg4Q8zRRqX57VL3P1yqzKWb5Pf51X1QL815fYbWL9qiJTNXqayk\nTPHNG6qoqMjqqCpzl8lvc2h478dkt9tVq34dRYfW+t9PBACcN2rXrq2PPpiiITcPkcNpl9fj07SP\np8nhcGjixIk6evSoevfuzQXvYBqKNirNU+7RN2/9W216d5XNbtPCj7+Vz+vVVfcPVEyTOAW5gvXV\ny58GxCfwWlG11LRtom595h75PF5tWb5Z2WsOWx0LAFDFrrjiCh05dERZWVmKi4uTx+NRcreuUqRL\ntRrG6rUb31D6M89q6J3Wri3C+YnFkKi0kPBQdb0hVT2GXClJWjV9vr6bPFOu4GBdkNJeRTmFytuf\nrdUrv7e8bO/du1edk7uoUYdmcgQ79cPC9Zoza46Sk5N16NAhhYSEqFYtRrgBoLqZPHmyxr82Qdc/\nca8Mw1DWrgP69JFXdOLYcaujSZLKysp05MgRxcbGyuVyWR0HP2IxJExn2G2Kqlun4jiybh3ZbDbV\nrl1Ha79drcylG3Vlvyt/cRVPK8THx+vi7t21YcFarft2tRISmysmJkYdu3RRqzYXqH6DBrrv/vv5\nsAYA1Ux+fr5qxERVLJaPjKutwoJCi1Od9N133ymufj116NJZsXXjNHPmTKsj4QwxdQSV5i33aP47\n01W7YV3Z7HZ9++ZncpeVq1bbFurz7MMqKyzSZ0+8oF49UzRgwABLs748caLW79imtLcnyO5wavHr\nk5Xa93LVbNFMN426T+UlpfrqmZfU7f33deutt1qaFQBQdXr37q1HH39MTbq0Vkzj+lo0+UtdcWU/\nq2OpsLBQA24YqEv+eKfi27RS1raduiUtTdu3blVMTIzV8XCaGNFGpTmCgxURF6f3R76kycOfV3DN\nmrI5nWrRu6cMw5ArIlwNurTXqu+t3YtUklasWqmajRvom5de16xxLyukdpSOHD2q5r0vkWGzKTgs\nVA27dtSKVSutjgoAqEItW7bUp9M+0dop8zTloZeUVKeR3n93stWxtHv3boVERCi+TStJUmxSM9WK\nr6utW7danAxngqKNSvN7vDq6Y4863nyLOt92u07sPSRvuVsHNmyWJHk9Hh3dskPNmja1OKkUEhSs\nzd9kqF6HTmrco6c2z10oh82ugxsyJUk+r09HM7cpoWkzi5MCAKpa7969tWVTpo4eydLHH34UENvS\n1qtXTwXZ2co9dESSVHD8hE4cOKSGDRtanAxngsWQqLTwyEgl9ElVzr59ks+n2omJyvzyK7kcDslh\nl7vcrW5dkzX7q3/L4bB2VtJNt96qLe4y1axfXz6PVz6vV8cXLlT28RMKj4lWcV6+Ehs31dzZsxUc\nzP7aAHA+mzJlipYvX64ePXpo4MCBVsf5VW+//baGjxihuIQmytq5W4898oiGPzjc6ljQ6fdOijYq\nLSg0VD6fT+Fx8TLsdhUc2CvJL8lQVNMkleQcl9Pr0f7duxQeHm5p1iG33KwZs7+WKypa9mCXCvbv\nUVJCMy2YN08rV65UaGiounXrJrvdbmlOAIC5+lzRTxkLFyqySaJyd21X3z6pmjn9C6tj/aqdO3dq\ny5YtSkhIUPPmza2Ogx9RtGE6e3Cw4rv21AU33ilJ2jpjivYs+FoXDB6q+p27y+/zacXLT+nyTu31\n0UcfWZo17bbb9W3mdrW77QEZhqEdsz9XxNG9+n75cktzAQCqzrJly9SjVy/1HDtBrppRKsk+rgVP\nDNfa71epbdu2VsfDOeR0eye7jqDSbHan3EVF+nbUPfL7fIpufoEMw65azVpIkgybTbUSW2nv3r0W\nJ5WKy8oU3aJNxfZNtRJbqejgTotTAQCq0saNGxUSVVuumiev7RBSq7ZcNSO1efNmijaqBIshUWme\n8lLl7tutdg88rQ4PjlfBkcPyut3a9c2X8vt8Ks3L0YFl36lZM+sXGPbsfrGOrVgod0mxfB6PDi/+\nVt27dbM6FgCgCqWmpqok+5iOb9koSTq6ea3K8vPUs2dPi5OhumBEG5Vmdwar0eV/UEjtOElSk35D\n9MOHL+vQ90u0f8k8+X0+BUfVUYMAWCE97L77tGTpMn0y6h7JMJTctaueH59udSwAQBVq0qSJnhs3\nTiNHP3xyRZFhaOJLL6pevXpWR0M1wYg2Ks3v86k460DFcfHRA5LfL7/hUGSX/qrRppfcxUVyBcAu\nHjt37tTsOV8rqtPlikq+Whs2btKqVausjgUAqGLDhw9XaXGRMjduUGlRoYYNG2Z1JFQjjGij0nw+\nnw5kzFTJiSOy2R06tm6pfH5DjQePVFij1pKkg5+/GBCLVJ9/8SW52vZW7ZTBkqTcmAb629intODb\n7tq1a5dCQ0MVHx9vcUoAQFUoLi6W1+tVSUlJQOyZjeqDEW1UmmF3ylEzRsc3rtLRdctlj6gtw+GQ\nI7xWxWOcNevI7fZYmPKkvPwC2cKjKo6dEbV0/PhxtW53oTp1T1FSqza66dbb5PP5LEwJADDbZ599\nprrxDXVx736qG99QX375pdWRUI1QtFFpfneZbDVi1fDBqWo4fKqcsU3l93h06Mt/qjRrrwq2fa8T\nK2cpJMRldVS5nA4d+26KivZsUsmhnTo8+01lZWXpRFRL1brzDdW5+y3NWvS9Jk2aZHVUAIBJjh49\nqrQ7hqrmwCcUedu/VOPaRzXkljTl5ORYHQ3VBFNHUGm2oBBFtE2VYT/51yaibapKdq+X1+3Rnvce\nlWHYFVSvuQoKCi1OKhWVlsmV0EWHZr0lv8+j4AYXqHjrYtVp1UuGYcgIcslomqzv16zTnXdanRYA\nYIadO3cquFZdBcclSJKC6zdXaUQt7d69W1FRUf/j2cCZY0QbleZzl6po6xL5/T75/X4VbV0mv6dc\nNp9HTQeNUf3U21V+cIvCw8OsjqrWLZoryFuiurdPUL2hryg4JFyRkVEq27lSkuT3uqX969W6JVfd\nAoDzVd26dZV7cJfc2QclSeXH9ysv6wC7jqDKcGVIVJrNFS5bsEu+kmLJMGQ4g+UvL1Gzm56QO/+Y\n7K5QFezepPv6tNETY8damrWkpETdeqRo08YNMgxDtWtHa8bnn6n/tQNU7PbLW16qi7oma/ZXM+R0\nOi3NCgAwx+rVq9Uz9QoVF+TLCAqR312ikNBwrVyyQK1bt7Y6Hs4hXBkSpvOXl8nv9yqycUsZNody\nd22Q3+PWnqlPq1aLLirNyVJZ3jEZfdpYHVUbN27Upk0bFR6fJEdwqI7uWKuZM2eqrKxUUU3aqbww\nR0eOHFZZWRlFGwDOU06nU+WlJXK4QhWV0F4529eovKxUDgf1B1WDv2moNJvTofrd+ivp2gckSbu+\nflf7Mqap5R9GKKZdT/n9fq197aGA+B/Y1dcOUGyHy9TyDyMkSXszpmr8ixOVdO0Dqtulr/x+v7Z9\n9JT++c9/avTo0RanBQCYITs7Wz6vVxeN+VBB4ZEqyz+hpU8PVmGh9WuJUD0wRxuVZnM4VbNRq4rj\nmg1byrDZFdHg5DxnwzAU2aSNiktKrIpYobCkVDUb/zyrJEU0bCHpZFZXvSTtP3jIknwAAPPt2LFD\nwZF1FBQeKUkKrhGtoIgobdu2zeJkqC4o2qg0b2mJ9s6fIndxgTylxdoz70P53GXaPXeyfF6PSrIP\n6+DSmTqalWV1VJUVF2rfd1NVXpgrb3mp9nzzvvxejw5nTJHP41Zp7jFlr56jS1N6Wh0VAGCS1q1b\nqzQnS8c2LZHf79fR9QtUXpCjtm3bWh0N1YT1v+PHucMRpKKj+7Xo0avl90s2Z7B8sqk8+7AyRvWV\nzW5XrYR2+mHLVquTSjanwmrX05InbpDf71ftpA4y7A61jHZo3ph+stls+tsjf9P1119vdVIAgEk2\nb94se3CINr3/pHzuctmcQbI5g7Vp0yYWQ6JKULRRaf7yYtmCXLrgqttls9u06d/vy+cuU8JlN6rO\nA11k2Oxa8epIuYKDrI4q+b0Kja6rqyZ8K7/Ppz2LZyhnT6bm/PtLlZWVyeFwyG63W50SAGCiunXr\nyu8pV0yz1mrYoaf2fD9f2fu2qUGDBlZHQzVB0UalOUPC1PbqoaoRGy/5fOo8+EF9/8k/tXryU6qd\n0E5lhbkqPnFE/ljrfyVXO7qW9i37t/IP7pDd6dLxHevksJ+cKRUcHGxxOgBAVfjss8/kcAarz1//\nKZvDoeaXXq+pf+qrzz//XD6fT7t27VLfvn0VExNjdVScpyjaqDS/DG2eNVmGzS7DZpO3vEzy+yWf\nV0VHdqmsqEAyDJWVlVkdVTabXTa7XcVH98nucMrhsJ/MCgCoNnJycuQIDpHx428wbQ6n7EEuvfve\nB5r4r1cVWjNaxffcq4/ef08DBw60OC3OR1ywBpVmDwpW4w7d1ffB52TI0LzXntCO5d8o+YZ71aH/\nrXKXlujTR26Vr/CEsrOzrc3qcKp+6866atTLstkdWjjpOW1d+JXKigsszQUAqDpfffWVrhs4SC17\n36DGXVK1c+lsbcv4Qq7wGhr8/CcKDovQDwu+1LL3X1BRfq7VcRHATrd3susIKs0ZHKKki/vK9uOI\ndtLFfWV3BimhW5+T97tC1KxrbxUVW7+9n+PHrHaHU4ZhKOmiy2XYbHr6mWfVul0Hdel2sebMmWN1\nTACAiQ4dOiSfz6ct8z/X1+Pv0/aFM+UpK1HjC3soOCxCkpTYLVUlhYExCHPs2DHdcONgtWjdRtdc\nd70OHDhgdSScIYo2Ks1dVqpti+fI5/PK7/Np25LZ8nnKtX3p1yfvLy3RzuXfVsyFtpK7tFhbF8+S\n1+OW3+/X1iWz5PN69PaH05R8ywg1vuxGDb75Fi1fvtzqqAAAk9SpU0d2u12dr/yDbn12ki68/HrZ\nncHas2aRSgvzJUnbl86V0xVicVLJ4/Hosj6X65DbpR53P6680FilXHqZSgLg2hQ4fUwdQaUFh0bI\n5rDLMH6co+0ul9/vl8/rUUhEpMqKCmTYbHIaPhUUWDs6EBQarhrRsSrIPiqb3aHgkFCVFuXrlmcm\nqW7CyQvZLJr6utrXduilF1+wNCsAwBwpKSla98MO/fHtryt6w0u39pK7rER+n0+hNWupKPeEPOVl\n8vu8lmbdsmWLeva+XHe/NkuGYUiSJg+/QVMnv62uXbtamg2n3ztZDInK8/lkyKH6CS1ls9u074cN\n8vm8kt+v+k2TVJBzXMcO7JHNaf22eT6vVwXHD6tJ2y4KDg3TD8vmyy9DJYV5FY8pK8hTSIP6FqYE\nAJgpKipK7tJi+Txu2Z1B8rrL5S0vlSu8hq57KF15Rw8pqm5Dvf/wbVZHlcvlUllJsTzlZXIGu+T1\nuFVaVCiXy2V1NJwBRrRRaUGuUF10zU3qd9cISdJ3U17Xd1Ne140P/11JHbvLsNs1+bH7tG/jShUX\nF1ua1RnsUue+A3XtHx+TJC2d8YG+njRBoaFh6njNrSrOPaGtC7/S9ytXqFGjRpZmBQCYY+jQoXr/\no4/VoGV7JSX30pal3+rg1g0qLy1W+z7XK65Jcy397B25iwtVXGTtb2L9fr8G3ThY67fvVZNOPbV/\n/XLVjwrR17P+LZvN+imZ1d15txhyzpw5atGihRITEzV+/Hir40CSw+lU/cSfrqRVL6GlbHaHFn02\nSY9dc6HGXttRfp9PvgD4AORwBqleQsuK47pNW8iw2TRtygdq6ihQcqMorVqxnJINAOexzZs3K6JW\nbbXo3EMn9m7TBRddqpAaNRUcGq6N82dq/uQJ8vu88rjLrY4qwzD01+EPKufALn37zt91ePtGPTxy\nBCX7HBeQf3per1cPPPCA5syZo8zMTE2ZMkU//PCD1bGqvbLSEs3/8FXlnziqorxsffPeP+Vxl6tu\nw8b653eZeuKjuTqye4tsP84tszRrSZEyPn5DuUcPq7ggT3PffVlet1uXXXaZXnv1Fb3w9+fVuHFj\nq2MCAEw0dOhQ5R/PUo3oGF3zwKNyhddQcV6O3OXleuz9WZo4b6Mu6jdAkdHRVkdVcXGxrrn2Og34\n06N6ddF23fLoCxr0hxst3y4XZyYgp44sW7ZMTzzxRMX2a+np6ZKk0aNHVzyGqSNVL7RGpEoK8hQS\nFi7JUElRgUIjaqqkMF8h4TXk83jkdIWovLhApaWllmaNjK6tvOwTcoWGybDZVFJYoJDwGiopzFdo\nRA35vF6VFhfxdwgAzmNvvfWW7rrrLjmDguQMDlF5aUnF6HWwK0QOZ5CKC/Pl9/st/3mwadMmXXJZ\nqrwer3xejwybTWGh4Xp0zEg9/ew4lZWVK6FZEy1dskR2u/Vroaqb82rqyMGDB9WgQYOK4/j4eB08\neNDCRJCkkoI8BbtCdP09wzXo/hFyhYapuCBPNWvH6KYHH1HfIXeqrLgwIK4MmZd9QkEul64d+ifd\n+MfRCo04WbIjomppyJ//pitvvUfOYFfFym4AwPnnrrvukis0TK27dNetI8aqZceuCg4JVVCwS5cO\nuEk3P/SYYuIbyRkcbHVU5ebmqqSwQA0SknTzQ48psc2Fys05ofvvf0Ctu/XSoD+O1qFjOWrcpKnV\nUfE7BOSuI5SfwBQaXkM3DBuhy2+8TZIUEh6h9/8+Vn996W01bdVOklSQe0LzPvvQwpQnBYeE6do7\nH9DVtw2TJNWsVUdvPjVCfx7/mlp16iZJKikq0pyP3rYyJgDAZMGuED304tuyOxy66PJrNLRna7Xu\n0l23/PVxSVKrTt300HUp1oaU1KNHD4WG19Cof7wnhzNI3a+4Tn/slyzDZuiOMc9Kktp3v1TDUjuq\npKREISHW7/2N/y0gi3b9+vW1f//+iuP9+/crPj7+F48bO3ZsxfcpKSlKSUmpgnTVl2EzFPxf/7Bd\nIWEyDEPBrtCK24J/vM1qNrshV2hYxXFwSMjJrP+VPyQ0TDab9VkBAOZxBAXJ9uNUC7vDIZvdLlfo\nf//cCrV82sh/2J0O2ewnq5lhs8kZFKyy0p8uWBMUfHKrP6/X2j2/q4OMjAxlZGSc8esE5Bxtj8ej\n5s2ba968eapXr566dOmiKVOmqGXLn3aRYI521TMMQ2E1aurux/8uu92hN58cobzs42qQ0EK3/nWs\njh0+oHfHP6ry0hLL/2wMw1BIWLjueux5hYSG6c2nRynn+FHF1m+o2x9+RnnHj+ntZ0arLACyAgDM\nYRgnB10u6X+DuqZepcWzPteSWV/I5/dpyJ//poaJLTT1X89p77YfVFpUaGnWl19+WaPH/E1dU6/S\nJf1v0Mr5s/XdF1NUVlqqIX8eo2at2+mLt17WwR1blH38mKVZq6PT7Z0BWbQlafbs2frLX/4ir9er\nO++8Uw8//PDP7qdoW8MwDIXXjJQkFeXnye/3yxkcrODgEPn9fhUV5AXMn8vJDwaRMgypqLBAfq9X\ndmeQQkJPjl78Jz8A4Pz1n4EXm90hn9ejkh8LdWhEDRmGTe7yMqXdcrPeeOMNi5NKYWFh8hu2H7N6\nVVJUoDfeeEMjRj8sr9enqMgaWr1qlerUqWN11GrnvCva/wtFGwAAAFXhvNp1BAAAADjXUbQBAAAA\nE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAAT\nULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQ\ntAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0\nAQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNQtAEAAAATULQB\nAAAAE1C0AQAAABNQtAEAAAATULQBAAAAE1C0AQAAABNYVrRHjBihli1bql27dhowYIDy8vIq7hs3\nbpwSExPVokULzZ0716qIAAAAwGmzrGj36dNHmzdv1vr165WUlKRx48ZJkjIzMzV16lRlZmZqzpw5\nGjZsmHw+n1Ux8SsyMjKsjlCtcf6tw7m3FuffWpx/63Duz02WFe3U1FTZbCffPjk5WQcOHJAkzZgx\nQ4MHD5bT6VTjxo2VkJCglStXWhUTv4J/8Nbi/FuHc28tzr+1OP/W4dyfmwJijvY777yjfv3+r737\nj4m6/uMA/jw6WiwqQOoIPAd3QHDcD66w6yyZt0IOM/ohKbDKlWOOls4KJrM/tDZB3VpSZnPN0CKb\n1DRjBgsqyBMJCwKWP3YVzAvEScDI6XaHvr9/uG76BfQjcj/4+Hxs783P+/O+48XLc++X73vfvRcB\nAPr7+zF79mzvvdmzZ6Ovry9QoRERERERTYnSl0+elZWFgYGBcf3l5eV46qmnAAAbN27E7bffjsLC\nwkmfR6FQ+CxGIiIiIiKfEAFUVVUl5s2bJy5cuODtq6ioEBUVFd7r7Oxs0draOu6xWq1WAGBjY2Nj\nY2NjY2PzadNqtVOqdRVCCIEAqK+vx5tvvonm5mZER0d7+48dO4bCwkK0tbWhr68PTzzxBP744w+u\nahMRERHRjOLTrSPXsmrVKrjdbmRlZQEArFYrtm/fDp1Oh6VLl0Kn00GpVGL79u0ssomIiIhoxgnY\nijYRERERkZwFxbeOSDE0NISsrCwkJydj4cKFGBkZGTfG5XLBZrMhLS0Ner0e77//fgAilZf6+nqk\npKQgKSkJmzdvnnDM6tWrkZSUBJPJhI6ODj9HKG/Xy//nn38Ok8kEo9GIRx99FF1dXQGIUp6kvPYB\n4OjRo1Aqldi3b58fo5M/KflvamqC2WyGXq/HggUL/BugjF0v94ODg7Db7UhPT4der8euXbv8H6RM\nvfLKK1CpVDAYDJOO4ZzrO9fL/5Tm3Cnt7A6A0tJSsXnzZiGEEJs2bRJr164dN+b06dOio6NDCCHE\nv//+K5KTk8WxY8f8GqecjI2NCa1WK3p6eoTb7RYmk2lcPg8ePChycnKEEEK0trYKi8USiFBlSUr+\nW1paxMjIiBBCiLq6OuZ/mkjJ/X/jbDabePLJJ8VXX30VgEjlSUr+h4eHhU6nEy6XSwghxNmzZwMR\nquxIyf369etFWVmZEOJy3qOiooTH4wlEuLLz008/ifb2dqHX6ye8zznXt66X/6nMuTNmRfubb77B\n8uXLAQDLly/H119/PW5MTEwM0tPTAQDh4eFITU1Ff3+/X+OUk7a2NiQmJiI+Ph6hoaHIz8/HgQMH\nrhpz5d+LxWLByMgIzpw5E4hwZUdK/q1WK+655x4AVx/8RDdHSu4B4IMPPkBeXh7uvffeAEQpX1Ly\nv2fPHixZssR77sKVH6qnqZOS+/vvvx+jo6MAgNHRUcyaNQtKZcA+8iUr8+fPR2Rk5KT3Oef61vXy\nP5U5d8YU2mfOnIFKpQIAqFSq676went70dHRAYvF4o/wZKmvrw9qtdp7PdHhQRONYbE3PaTk/0o7\nd+70HvxEN0fqa//AgQMoLi4GwO/7n05S8u90OjE0NASbzYaMjAx89tln/g5TlqTkvqioCL///jti\nY2NhMplQWVnp7zBvWZxzg4fUOTeo/gs62QE3GzduvOpaoVBcc1I7d+4c8vLyUFlZifDw8GmP81Yh\ntXAQ//d5WhYc0+NG8vjjjz/ik08+weHDh30Y0a1DSu7XrFmDTZs2QaFQQAgx7t8BTZ2U/Hs8HrS3\nt+P777/H+fPnYbVa8cgjjyApKckPEcqXlNyXl5cjPT0dTU1N+PPPP5GVlYXOzk7cddddfoiQOOcG\n3vx092kAAAbJSURBVI3MuUFVaDc0NEx6T6VSYWBgADExMTh9+jTuu+++Ccd5PB4sWbIEL7zwAp55\n5hlfhXpLiIuLg8vl8l67XC7v27STjfn7778RFxfntxjlTEr+AaCrqwtFRUWor6+/5lteJJ2U3P/6\n66/Iz88HcPnDYXV1dQgNDUVubq5fY5UjKflXq9WIjo5GWFgYwsLCkJmZic7OThbaN0lK7ltaWvDW\nW28BALRaLRISEnDy5ElkZGT4NdZbEefcwLvROXfGbB3Jzc3F7t27AQC7d++esIgWQmDFihXQ6XRY\ns2aNv0OUnYyMDDidTvT29sLtdmPv3r3jiojc3Fx8+umnAIDW1lZERER4t/jQzZGS/1OnTuG5555D\ndXU1EhMTAxSp/EjJ/V9//YWenh709PQgLy8PH330EYvsaSIl/08//TQcDgcuXryI8+fP4+eff4ZO\npwtQxPIhJfcpKSlobGwEcHlb58mTJ6HRaAIR7i2Hc25gTWXODaoV7WspKyvD0qVLsXPnTsTHx6Om\npgYA0N/fj6KiIhw8eBCHDx9GdXU1jEYjzGYzAKCiogJ2uz2Qoc9YSqUS27ZtQ3Z2Ni5evIgVK1Yg\nNTUVO3bsAACsXLkSixYtwrfffovExETceeedqKqqCnDU8iEl/++88w6Gh4e9+4RDQ0PR1tYWyLBl\nQUruyXek5D8lJQV2ux1GoxEhISEoKipioT0NpOR+3bp1ePnll2EymXDp0iVs2bIFUVFRAY5cHgoK\nCtDc3IzBwUGo1Wq8/fbb8Hg8ADjn+sP18j+VOZcH1hARERER+cCM2TpCRERERDSTsNAmIiIiIvIB\nFtpERERERD7AQpuIiIiIyAdYaBMRERER+QALbSIiIiIiH2ChTURERETkAyy0iYiChMvlgkajwfDw\nMABgeHgYGo0Gp06dmvJz7tq1C6tWrZrwXkFBAUwmE7Zu3Yr8/HyYzWaYzWYkJCR4D/0CLh85bLVa\nodfrYTQa4Xa7AQBVVVUwGAwwmUzIycnBP//8M+U4iYjkaMacDElEJHdqtRrFxcUoKyvDjh07UFZW\nhpUrV2LOnDnT/rMGBgbwyy+/wOl0jrtXUlKCiIgIAMDY2BhefPFFVFdXw2AwYHh4GEqlEm63GyUl\nJXA6nYiKisLatWuxbds2rF+/ftpjJSKaqbiiTUQURF5//XW0trZi69ataGlpQUlJyYTjmpqakJmZ\nicWLFyMlJQXFxcX476DfqqoqPPDAA7BYLGhpaZnw8QsXLkRfXx/MZjMcDoe3XwiBmpoaFBQUAAC+\n++47GI1GGAwGAEBkZCRCQkKgVCoRGRmJc+fOQQiB0dFRxMXFTWcqiIhmPK5oExEFEaVSiS1btiAn\nJwcNDQ247bbbJh179OhRHD9+HHPmzIHdbse+ffswb948bNiwAe3t7bj77rths9nw4IMPjntsbW0t\nFi9ejI6Ojqv6Dx06BJVKBa1WCwBwOp1QKBSw2+04e/Ys8vPzUVpaipCQEFRWVkKv1yM8PBzJycn4\n8MMPpzcZREQzHFe0iYiCTF1dHWJjY9Hd3X3NcQ8//DDi4+MREhKCgoICOBwOtLW1YcGCBZg1axZC\nQ0OxbNky70r3lSbqA4AvvvgChYWF3muPxwOHw4E9e/bA4XBg//79+OGHHzA6OorVq1ejs7MT/f39\nMBgMqKiouLlfnIhIZlhoExEFkd9++w2NjY04cuQI3nvvPQwMDEw6VqFQeP8shLjq+sp+qcbGxrB/\n/34sW7bM26dWq5GZmYmoqCiEhYVh0aJFaG9vx4kTJ5CQkICEhAQAwPPPPz/pNhUiolsVC20ioiAh\nhEBxcTEqKyuhVqtRWlo66R5tAGhra0Nvby8uXbqEmpoazJ8/HxaLBc3NzRgaGoLH48GXX34p+ec3\nNjYiNTUVsbGx3r7s7Gx0d3fjwoULGBsbQ3NzM9LS0qDRaHDixAkMDg4CABoaGqDT6ab+yxMRyRAL\nbSKiIPHxxx8jPj4ejz/+OADg1VdfxfHjx3Ho0KFxYxUKBebOnYvXXnsNOp0OGo0Gzz77LGJiYrBh\nwwZYrVY89thjSEtL865019bWXvWtIP+/Ar53717vhyD/ExERgTfeeANz586F2WzGQw89hJycHERH\nR6O8vBw2mw0mkwldXV1Yt27ddKeEiGhGU4gbeV+RiIiCQlNTE959913U1tYGOhQiIpoEV7SJiGYg\nhUIx4Z5sIiIKHlzRJiIKYt3d3XjppZeu6rvjjjtw5MiRAEVERERSsdAmIiIiIvIBbh0hIiIiIvIB\nFtpERERERD7AQpuIiIiIyAdYaBMRERER+QALbSIiIiIiH/gfQ0klYoBiooAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0xc9bf780>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "        explore the 'loss' column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size(X_pd.loss[X_pd.loss > 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "        You will do many such exploration to understand the data better"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_pd.loss.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Let's transform the data into two dimensional numpy array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.asarray(X_pd.values, dtype = float)\n",
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Check for missing values in the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.where(np.isnan(X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X[1][329]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_pd['f330'].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Imputation of Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import Imputer\n",
      "imputer = Imputer(strategy='mean')\n",
      "\n",
      "X = imputer.fit_transform(X)\n",
      "\n",
      "print \"Since we have replaced nan with mean, the following should not return a null array\"\n",
      "np.where(np.isnan(X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X[1][329]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Separate the features and the labels"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "label is also known as target variable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "\n",
      "print \"Let's extract labels from the data\"\n",
      "labels = np.asarray(X[:,-1], dtype = float)\n",
      "print \"Now Let's extract the features\"\n",
      "data = np.asarray(X[:,1:-2], dtype = float)\n",
      "\n",
      "print \"Some random data before scaling\", '>' * 5, data[10][357]\n",
      "data = preprocessing.scale(data)\n",
      "print \"The same data after scaling\", '>' * 5, data[10][357]\n",
      "print data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are interested in the classification problem. Whether the customer will default or not.\n",
      "\n",
      "So if loss contains a number more than zero (0), it means that the customer defaulted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = np.asarray(map(int,labels))\n",
      "\n",
      "bin_labels = np.zeros(len(labels))\n",
      "bin_labels[labels>0] = 1\n",
      "    \n",
      "''' \n",
      "let's take some random labels and compare the result of before and after binarization\n",
      "'''\n",
      "print \"Original labels:  \", labels[50:70]\n",
      "print \"binarized labels: \", bin_labels[50:70]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Correlation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pearson Correlation gives us a number between -1 and 1 to signify the correlation between two entities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl.figure(2, figsize=(15, 6))\n",
      "# Correlated features : f2, f222, f527_diff_f528, f528_diff_f274, f332\n",
      "#pl.scatter((X_pd.f527 - X_pd.f528), bin_labels, c=bin_labels, cmap=pl.cm.Paired)\n",
      "pl.scatter(X_pd.f436, X_pd.loss, c=X_pd.loss, cmap=pl.cm.prism_r)\n",
      "pl.xlabel('X_pd.f222')\n",
      "pl.ylabel('X_pd.loss')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats as stats\n",
      "corr = stats.pearsonr(data[:,222], labels)\n",
      "print \"Pearson Correlation\", abs(corr[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "?stats.pearsonr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Separate train and test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "a_train, a_test, b_train, b_test = train_test_split(data, bin_labels, test_size=0.2, random_state=42)\n",
      "\n",
      "print \"Shape of test labels\", b_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Apply Machine Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To train and build a model"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "        Gaussian Naive Bayes Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "from time import time\n",
      "\n",
      "gnb = GaussianNB()\n",
      "\n",
      "t0 = time()\n",
      "gnb.fit(a_train, b_train)\n",
      "print \"Training time for GaussianNB\", 10 * '>', \": %0.3fs\" % (time() - t0)\n",
      "#pred = model.predict(a_test)\n",
      "print \"GaussianNB SCORE  :\", gnb.score(a_test, b_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "        Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "from time import time\n",
      "\n",
      "lg = LogisticRegression()\n",
      "\n",
      "t0 = time()\n",
      "lg.fit(a_train, b_train)\n",
      "print \"Training time for Logistic Regression\", 10 * '>', \": %0.3fs\" % (time() - t0)\n",
      "#pred = model.predict(a_test)\n",
      "print \"Logistic Regression SCORE:\", lg.score(a_test, b_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "\n",
      "        Find the accuracy of other classifiers\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "models = { #'LogisticRegression': LogisticRegression(), # We have already seen\n",
      "            'Support Vector Classifier': SVC(),\n",
      "            #'GradientBoostingClassifier': GradientBoostingClassifier(), #takes very high training time 160+ sec\n",
      "            'KNN': KNeighborsClassifier(),\n",
      "            #'GaussianNB': GaussianNB(),\n",
      "            'Decision Tree Classifier': DecisionTreeClassifier()\n",
      "         }\n",
      "\n",
      "for i, (model_name, model) in enumerate(models.iteritems()):\n",
      "        t0 = time()\n",
      "        model.fit(a_train, b_train)\n",
      "        print \"Training time for\", model_name, 10 * '>', \": %0.3fs\" % (time() - t0)\n",
      "        print model_name, \"SCORE:\", model.score(a_test, b_test)\n",
      "        print 50 * '_'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "        Decision Tree Classifier:\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Combining two classifiers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "predictions = []\n",
      "\n",
      "estimators = [  KNeighborsClassifier(), \\\n",
      "            DecisionTreeClassifier()\n",
      "         ]\n",
      "\n",
      "for i, est in enumerate(estimators):\n",
      "    est.fit(a_train, b_train)\n",
      "    pred = est.predict_proba(a_test)\n",
      "    print \"Estimator:\",i, metrics.roc_auc_score(b_test, array(pred[:,1]))\n",
      "    predictions.append(array(pred[:,1]))\n",
      "\n",
      "\n",
      "final_proba = predictions[0] * 0.75 + predictions[1] * 0.25\n",
      "final_prediction = []\n",
      "\n",
      "'''\n",
      "for i in range(len(final_proba)):\n",
      "    if final_proba[i] > 0.7:\n",
      "        final_prediction.append(1)\n",
      "    else:\n",
      "        final_prediction.append(0)\n",
      "       \n",
      "print \"Classification Score of Ensembling two models\", metrics.accuracy_score(b_test, final_prediction)\n",
      "'''\n",
      "print \"Classification Score of Ensembling two models\", metrics.roc_auc_score(b_test, final_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_proba = predictions[0] * 0.35 + predictions[1] * 0.65\n",
      "roc = metrics.roc_curve(b_test, final_proba)\n",
      "print \"Classification Score of Ensembling two models\", \n",
      "\n",
      "pl.plot(roc[0], roc[1],color='r',lw=2)\n",
      "pl.fill_between(roc[0], roc[1],1e-6,color='0.7')\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Selection:\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "let's try to get the most important features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "lsvc = LinearSVC(penalty=\"l1\", dual=False)\n",
      "lsvc.fit(a_train, b_train)\n",
      "a_train_trfmd = lsvc.transform(a_train)\n",
      "a_test_trfmd =  lsvc.transform(a_test)\n",
      "\n",
      "a_test_trfmd.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn = KNeighborsClassifier()\n",
      "\n",
      "t0 = time()\n",
      "knn.fit(a_train_trfmd, b_train)\n",
      "print \"Training time for KNN\", 10 * '>', \": %0.3fs\" % (time() - t0)\n",
      "print \"SVC SCORE:\", knn.score(a_test_trfmd, b_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n",
      "Cross Validation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Hyperparameter estimation: Grid Search"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Grid search with SVC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import grid_search\n",
      "\n",
      "parameters = {\n",
      "              'C': np.logspace(-2, 2, 10) #,\n",
      "              #'kernel': ['linear', 'rbf', 'sigmoid']\n",
      "              }\n",
      "    \n",
      "clf = grid_search.GridSearchCV(svc, parameters, cv=2)\n",
      "clf.fit(a_train_trfmd, b_train)\n",
      "\n",
      "print 'grid_scores_', clf.grid_scores_\n",
      "#print 'best_estimator_', clf.best_estimator_\n",
      "print 'best_score_', clf.best_score_\n",
      "print 'best_params_', clf.best_params_\n",
      "\n",
      "# best_params_ {'kernel': 'rbf', 'C': 0.01}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = [g[1] for g in clf.grid_scores_]\n",
      "plt.semilogx(parameters['C'], scores);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0, \\\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None, \\\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "print svc.fit(a_train_trfmd, b_train).score(a_test_trfmd, b_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from sklearn import metrics\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "y_pred = svc.predict(a_test_trfmd)\n",
      "\n",
      "def plot_confusion_matrix(y_pred, y):\n",
      "    plt.imshow(metrics.confusion_matrix(y, y_pred),\n",
      "               cmap=plt.cm.binary, interpolation='nearest')\n",
      "    plt.colorbar()\n",
      "    plt.xlabel('true value')\n",
      "    plt.ylabel('predicted value')\n",
      "    \n",
      "print \"Classification Accuracy Score:\", metrics.accuracy_score(b_test, y_pred)\n",
      "\n",
      "plot_confusion_matrix(b_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Grid Search with K Nearest Neighbors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.arange(3, 31, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import grid_search\n",
      "\n",
      "knn = KNeighborsClassifier()\n",
      "\n",
      "parameters = {\n",
      "              'n_neighbors': np.arange(5, 12, 2)\n",
      "              }\n",
      "    \n",
      "clf = grid_search.GridSearchCV(knn, parameters, cv=3)\n",
      "clf.fit(a_train_trfmd, b_train)\n",
      "\n",
      "print 'grid_scores_', clf.grid_scores_\n",
      "#print 'best_estimator_', clf.best_estimator_\n",
      "print 'best_score_', clf.best_score_\n",
      "print 'best_params_', clf.best_params_\n",
      "\n",
      "# best_params_ {'kernel': 'rbf', 'C': 0.01}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn = KNeighborsClassifier(n_neighbors=11)\n",
      "parameters = {\n",
      "              'leaf_size' : [20,30,40,50,100]\n",
      "              }\n",
      "    \n",
      "clf = grid_search.GridSearchCV(knn, parameters, cv=3)\n",
      "clf.fit(a_train_trfmd, b_train)\n",
      "\n",
      "print 'best_score_', clf.best_score_\n",
      "print 'best_params_', clf.best_params_\n",
      "\n",
      "# best_params_ {'kernel': 'rbf', 'C': 0.01}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use a 5 fold cross validation and with scoring as precision"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "# Let's do a 5-fold cross-validation of the SVC estimator\n",
      "print cross_val_score(KNeighborsClassifier(n_neighbors=11, leaf_size=20), data, labels, cv=5, scoring='precision')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Visualizing the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reduce the dimension of the training set by using Principal Component Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA\n",
      "\n",
      "pca = PCA(n_components=2)\n",
      "\n",
      "pca_X = pca.fit_transform(a_train_trfmd)\n",
      "\n",
      "pca_X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "\n",
      "import pylab as pl\n",
      "\n",
      "pl.figure(2, figsize=(8, 6))\n",
      "#pl.clf()\n",
      "\n",
      "# Plot the training points from PCA\n",
      "pl.scatter(pca_X[:, 0], pca_X[:, 1], c=b_train, cmap=pl.cm.Paired)\n",
      "pl.xlabel('X-component')\n",
      "pl.ylabel('Y-component')\n",
      "\n",
      "#pl.xlim(x_min, x_max)\n",
      "#pl.ylim(y_min, y_max)\n",
      "#pl.xticks(())\n",
      "#pl.yticks(())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Finally, if we want to serialize the model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "so that we can use it later on...\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "''' dump the model '''\n",
      "import cPickle as cpkl\n",
      "with open(\"GIDS.pickle\", \"wb\") as f:\n",
      "    cpkl.dump(knn, f)\n",
      "\n",
      "''' load the model '''\n",
      "with open(\"GIDS.pickle\", \"rb\") as f:\n",
      "    cpkl.load(knn, f)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}